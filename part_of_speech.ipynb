{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:#FFFF00\">\n",
    " taggend_sents\n",
    "<h3>\n",
    "  we will use the tagged corpus (Penn Treebank & Brown) \n",
    "</h3>\n",
    "<h3>\n",
    "use .tagged_sents to get the tagged sentences in corpus\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./picture/part_of_speech.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank, brown\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "print(treebank.tagged_sents()[0])\n",
    "#[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
    "print(brown.tagged_sents()[0])\n",
    "#[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:#FFFF00\">\n",
    " record\n",
    "<h3>\n",
    "  use defaultdict\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report\n",
      "{'NNP': 8, 'VB': 9, 'NN': 31}\n",
      "point\n",
      "{'NN': 26, 'VBP': 2, 'VB': 1}\n",
      "%\n",
      "{'NN': 445, 'JJ': 1}\n",
      "week\n",
      "{'NN': 55, 'NNP': 1}\n",
      "ended\n",
      "{'VBD': 22, 'VBN': 3}\n",
      "assume\n",
      "{'VBP': 2, 'VB': 2}\n",
      "current\n",
      "{'JJ': 32, 'NN': 2}\n",
      "'\n",
      "{'POS': 63, \"''\": 10}\n",
      "investments\n",
      "{'NNS': 17, 'NNPS': 1}\n",
      "day\n",
      "{'NN': 23, 'NNP': 1}\n",
      "longer\n",
      "{'JJR': 5, 'RBR': 4, 'RB': 1}\n",
      "thought\n",
      "{'VBN': 2, 'VBD': 5, 'NN': 1}\n",
      "indicate\n",
      "{'VB': 2, 'VBP': 1}\n",
      "because\n",
      "{'IN': 122, 'RB': 2}\n",
      "permit\n",
      "{'VBP': 1, 'VB': 2}\n",
      "sign\n",
      "{'NN': 9, 'VB': 3}\n",
      "can\n",
      "{'MD': 94, 'NN': 1}\n",
      "sooner\n",
      "{'RB': 1, 'RBR': 1}\n",
      "open\n",
      "{'JJ': 7, 'VB': 2, 'NNP': 1}\n",
      "only\n",
      "{'RB': 73, 'JJ': 10}\n",
      "watch\n",
      "{'VBP': 3, 'NN': 4, 'VB': 4}\n",
      "market\n",
      "{'NN': 178, 'NNP': 8}\n",
      "reached\n",
      "{'VBD': 4, 'VBN': 14}\n",
      "may\n",
      "{'MD': 70, 'NNP': 12}\n",
      "blip\n",
      "{'VB': 1, 'VBP': 1}\n",
      "down\n",
      "{'RP': 14, 'RB': 22, 'NNP': 1, 'IN': 19, 'NN': 1}\n",
      "bills\n",
      "{'NNS': 19, 'NNPS': 1}\n",
      "investors\n",
      "{'NNS': 66, 'NNPS': 3}\n",
      "continue\n",
      "{'VBP': 7, 'VB': 13}\n",
      "assets\n",
      "{'NNS': 18, 'NNPS': 1}\n",
      "beat\n",
      "{'VBP': 1, 'VB': 4, 'VBD': 1}\n",
      "go\n",
      "{'VB': 18, 'VBP': 4}\n",
      "after\n",
      "{'IN': 87, 'RB': 2}\n",
      "top\n",
      "{'JJ': 10, 'VB': 1, 'NN': 1}\n",
      "currently\n",
      "{'RB': 26, 'NNP': 1}\n",
      "yielding\n",
      "{'VBG': 3, 'JJ': 1, 'NN': 1}\n",
      "world-wide\n",
      "{'NNP': 1, 'JJ': 5}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "POS_dict = defaultdict(dict)\n",
    "\n",
    "for word_pos_pair in treebank.tagged_words():\n",
    "    #word_pos_pair would be like [('Pierre', 'NNP'),('Vinken', 'NNP')]\n",
    "    #print(word_pos_pair)\n",
    "    word = word_pos_pair[0].lower() # word\n",
    "    POS = word_pos_pair[1] # part_of_speech\n",
    "    POS_dict[word][POS] = POS_dict[word].get(POS,0)+1\n",
    "\"\"\" POS_dict willbe like {\n",
    "    \"target\":{'NN': 8, 'VB': 2}\n",
    "    forecast:{'NN': 4, 'VBP': 1, 'VBD': 1, 'VBN': 1}\n",
    "    recorded:{'VBN': 1, 'VBD': 1}\n",
    "}\n",
    "\"\"\"\n",
    "for word in list(POS_dict.keys())[400:500]:\n",
    "    if(len(POS_dict[word]))>1:\n",
    "        print(word)\n",
    "        print(POS_dict[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:#FFFF00\">\n",
    "Unigram Tagger\n",
    "</h1>\n",
    "<h3>\n",
    "  however one word will not only have one part_of_speech\n",
    "</h3>\n",
    "<h3>\n",
    "    so we choose the most commen part_of_speech\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You', 'NN'), ('better', 'JJR'), ('start', 'VB'), ('swimming', 'NN'), ('or', 'CC'), ('sink', 'VB'), ('like', 'IN'), ('a', 'DT'), ('stone', 'NN'), (',', ','), ('cause', 'NN'), ('the', 'DT'), ('times', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('-', ':'), ('changing', 'VBG'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_dict = {}\n",
    "#print(POS_dict)\n",
    "for word in POS_dict:\n",
    "    tagged_dict[word] = max(POS_dict[word],key=lambda x: POS_dict[word][x])\n",
    "def tag(sentence):\n",
    "    return [(word,tagged_dict.get(word,\"NN\")) for word in sentence]\n",
    "\n",
    "example_sentence = \"\"\"You better start swimming or sink like a stone , cause the times they are a - changing .\"\"\".split() \n",
    "print(tag(example_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:#FFFF00\">\n",
    "NLTK's Unigram Tagger\n",
    "</h1>\n",
    "<h3>\n",
    "in here unigram tagger is better than bigram agger \n",
    "because bigram tagger do not have enough data (relation in sentence)\n",
    "and if there is one None all will be None\n",
    "\n",
    "\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20596\\2413824092.py:10: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(unigram_tagger.evaluate(test_sents))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20596\\2413824092.py:12: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(bigram_tagger.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627989821882952\n",
      "[('You', 'PRP'), ('better', 'JJR'), ('start', 'VB'), ('swimming', None), ('or', 'CC'), ('sink', 'VB'), ('like', 'IN'), ('a', 'DT'), ('stone', 'NN'), (',', ','), ('cause', 'NN'), ('the', 'DT'), ('times', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('-', ':'), ('changing', 'VBG'), ('.', '.')]\n",
      "0.13455470737913486\n",
      "[('You', 'PRP'), ('better', None), ('start', None), ('swimming', None), ('or', None), ('sink', None), ('like', None), ('a', None), ('stone', None), (',', None), ('cause', None), ('the', None), ('times', None), ('they', None), ('are', None), ('a', None), ('-', None), ('changing', None), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "size = int(len(treebank.tagged_sents())*0.9)\n",
    "train_sents = treebank.tagged_sents()[:size]\n",
    "test_sents = treebank.tagged_sents()[size:]\n",
    "\n",
    "\n",
    "from nltk import UnigramTagger, BigramTagger\n",
    "\n",
    "unigram_tagger = UnigramTagger(train_sents)\n",
    "bigram_tagger = BigramTagger(train_sents)\n",
    "print(unigram_tagger.evaluate(test_sents))\n",
    "print(unigram_tagger.tag(example_sentence))\n",
    "print(bigram_tagger.evaluate(test_sents))\n",
    "print(bigram_tagger.tag(example_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:#FFFF00\">\n",
    "backoffs\n",
    "</h1>\n",
    "<h3>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905852417302799\n",
      "[('You', 'PRP'), ('better', 'JJR'), ('start', 'VB'), ('swimming', 'NN'), ('or', 'CC'), ('sink', 'VB'), ('like', 'IN'), ('a', 'DT'), ('stone', 'NN'), (',', ','), ('cause', 'VB'), ('the', 'DT'), ('times', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('-', ':'), ('changing', 'VBG'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20596\\2827647605.py:6: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(bigram_tagger.evaluate(test_sents))\n"
     ]
    }
   ],
   "source": [
    "from nltk import DefaultTagger\n",
    "default_tagger =  DefaultTagger(\"NN\")\n",
    "unigram_tagger = UnigramTagger(train_sents,backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(train_sents,backoff=unigram_tagger)\n",
    "\n",
    "print(bigram_tagger.evaluate(test_sents))\n",
    "print(bigram_tagger.tag(example_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
